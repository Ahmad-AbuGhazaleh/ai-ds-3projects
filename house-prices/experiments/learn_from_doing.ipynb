{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61c658e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, KFold, cross_val_score\n",
    "from sklearn.metrics import root_mean_squared_error, r2_score\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import math\n",
    "from scipy.stats import skew\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c85fe91",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TRAIN = r\"..\\datasets\\train.csv\"\n",
    "PATH_TEST = r\"..\\datasets\\test.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f088e421",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(PATH_TRAIN)\n",
    "df_test = pd.read_csv(PATH_TEST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ffed632",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Shape Train:\", df_train.shape)\n",
    "print(\"Shape Test:\", df_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01cb1b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "DROPPED_COL = [\"Id\", \"Utilities\"]\n",
    "X = df_train.drop([\"SalePrice\", *DROPPED_COL], axis=1)\n",
    "y = df_train[\"SalePrice\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f83e27c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, X_temp, y, y_temp = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.543, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd38f3b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "\n",
    "class GroupMedianImputer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, group_col, target_col):\n",
    "        self.group_col = group_col\n",
    "        self.target_col = target_col\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        self.median_values = X.groupby(self.group_col)[\n",
    "            self.target_col].median()\n",
    "        self.global_median_ = X[self.target_col].median()\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        df = X.copy()\n",
    "        df[self.target_col] = df[self.target_col].fillna(\n",
    "            df[self.group_col].map(self.median_values))\n",
    "        df[self.target_col] = df[self.target_col].fillna(self.global_median_)\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23b8cbcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "ORDINAL_MAPS = [\n",
    "\n",
    "    # -------------------- Quality (Premium features) --------------------\n",
    "    {\n",
    "        \"columns\": [\n",
    "            \"ExterQual\", \"KitchenQual\", \"HeatingQC\"\n",
    "        ],\n",
    "        \"ordinalMap\": {\n",
    "            \"Ex\": 5,\n",
    "            \"Gd\": 4,\n",
    "            \"TA\": 3,\n",
    "            \"Fa\": 2,\n",
    "            \"Po\": 1,\n",
    "            np.nan: 0\n",
    "        }\n",
    "    },\n",
    "\n",
    "    # -------------------- Condition (Depreciation factors) --------------------\n",
    "    {\n",
    "        \"columns\": [\n",
    "            \"ExterCond\", \"BsmtCond\", \"GarageCond\"\n",
    "        ],\n",
    "        \"ordinalMap\": {\n",
    "            \"Ex\": 5,\n",
    "            \"Gd\": 4,\n",
    "            \"TA\": 3,\n",
    "            \"Fa\": 2,\n",
    "            \"Po\": 1,\n",
    "            np.nan: 0\n",
    "        }\n",
    "    },\n",
    "\n",
    "    # -------------------- Optional Feature Quality --------------------\n",
    "    {\n",
    "        \"columns\": [\n",
    "            \"BsmtQual\", \"FireplaceQu\", \"GarageQual\", \"PoolQC\"\n",
    "        ],\n",
    "        \"ordinalMap\": {\n",
    "            \"Ex\": 5,\n",
    "            \"Gd\": 4,\n",
    "            \"TA\": 3,\n",
    "            \"Fa\": 2,\n",
    "            \"Po\": 1,\n",
    "            np.nan: 0  # No feature present\n",
    "        }\n",
    "    },\n",
    "\n",
    "    # -------------------- Basement Finish / Exposure --------------------\n",
    "    {\n",
    "        \"columns\": [\"BsmtExposure\"],\n",
    "        \"ordinalMap\": {\n",
    "            \"Gd\": 4,\n",
    "            \"Av\": 3,\n",
    "            \"Mn\": 2,\n",
    "            \"No\": 1,\n",
    "            np.nan: 0\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"columns\": [\"BsmtFinType1\", \"BsmtFinType2\"],\n",
    "        \"ordinalMap\": {\n",
    "            \"GLQ\": 6,\n",
    "            \"ALQ\": 5,\n",
    "            \"BLQ\": 4,\n",
    "            \"Rec\": 3,\n",
    "            \"LwQ\": 2,\n",
    "            \"Unf\": 1,\n",
    "            np.nan: 0\n",
    "        }\n",
    "    },\n",
    "\n",
    "    # -------------------- Garage --------------------\n",
    "    {\n",
    "        \"columns\": [\"GarageFinish\"],\n",
    "        \"ordinalMap\": {\n",
    "            \"Fin\": 3,\n",
    "            \"RFn\": 2,\n",
    "            \"Unf\": 1,\n",
    "            np.nan: 0\n",
    "        }\n",
    "    },\n",
    "\n",
    "    # -------------------- Functional Rating (NEW) --------------------\n",
    "    {\n",
    "        \"columns\": [\"Functional\"],\n",
    "        \"ordinalMap\": {\n",
    "            \"Typ\": 8,   # Typical\n",
    "            \"Min1\": 7,  # Minor Deductions 1\n",
    "            \"Min2\": 6,  # Minor Deductions 2\n",
    "            \"Mod\": 5,   # Moderate Deductions\n",
    "            \"Maj1\": 4,  # Major Deductions 1\n",
    "            \"Maj2\": 3,  # Major Deductions 2\n",
    "            \"Sev\": 2,   # Severely Damaged\n",
    "            \"Sal\": 1    # Salvage only\n",
    "        }\n",
    "    },\n",
    "\n",
    "    # -------------------- Access Features --------------------\n",
    "    {\n",
    "        \"columns\": [\"PavedDrive\"],\n",
    "        \"ordinalMap\": {\n",
    "            \"Y\": 2,\n",
    "            \"P\": 1,\n",
    "            \"N\": 0\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"columns\": [\"Street\"],\n",
    "        \"ordinalMap\": {\n",
    "            \"Pave\": 1,\n",
    "            \"Grvl\": 0\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"columns\": [\"Alley\"],\n",
    "        \"ordinalMap\": {\n",
    "            \"Pave\": 2,\n",
    "            \"Grvl\": 1,\n",
    "            np.nan: 0  # No alley access\n",
    "        }\n",
    "    },\n",
    "\n",
    "    # -------------------- Binary Features --------------------\n",
    "    {\n",
    "        \"columns\": [\"CentralAir\"],\n",
    "        \"ordinalMap\": {\n",
    "            \"Y\": 1,\n",
    "            \"N\": 0\n",
    "        }\n",
    "    },\n",
    "\n",
    "    # -------------------- Lot Characteristics --------------------\n",
    "    {\n",
    "        \"columns\": [\"LotShape\"],\n",
    "        \"ordinalMap\": {\n",
    "            \"Reg\": 3,  # Regular\n",
    "            \"IR1\": 2,  # Slightly irregular\n",
    "            \"IR2\": 1,  # Moderately irregular\n",
    "            \"IR3\": 0   # Irregular\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"columns\": [\"LandContour\"],\n",
    "        \"ordinalMap\": {\n",
    "            \"Lvl\": 3,  # Near Flat/Level\n",
    "            \"Bnk\": 2,  # Banked\n",
    "            \"HLS\": 1,  # Hillside\n",
    "            \"Low\": 0   # Depression\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"columns\": [\"LandSlope\"],\n",
    "        \"ordinalMap\": {\n",
    "            \"Gtl\": 2,  # Gentle slope\n",
    "            \"Mod\": 1,  # Moderate slope\n",
    "            \"Sev\": 0   # Severe slope\n",
    "        }\n",
    "    },\n",
    "\n",
    "    # -------------------- Utilities / Electrical --------------------\n",
    "    {\n",
    "        \"columns\": [\"Electrical\"],\n",
    "        \"ordinalMap\": {\n",
    "            \"SBrkr\": 5,  # Standard Circuit Breakers\n",
    "            \"FuseA\": 4,  # Fuse Box over 60 AMP\n",
    "            \"FuseF\": 3,  # 60 AMP Fuse Box\n",
    "            \"FuseP\": 2,  # 60 AMP Fuse Box (Poor)\n",
    "            \"Mix\": 1,    # Mixed\n",
    "            np.nan: 0\n",
    "        }\n",
    "    },\n",
    "\n",
    "    # -------------------- Fence --------------------\n",
    "    {\n",
    "        \"columns\": [\"Fence\"],\n",
    "        \"ordinalMap\": {\n",
    "            \"GdPrv\": 4,  # Good Privacy\n",
    "            \"MnPrv\": 3,  # Minimum Privacy\n",
    "            \"GdWo\": 2,   # Good Wood\n",
    "            \"MnWw\": 1,   # Minimum Wood/Wire\n",
    "            np.nan: 0    # No Fence\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "\n",
    "def map_ordinal(X, verbose=False):\n",
    "    \"\"\"\n",
    "    Apply ordinal mappings with comprehensive error handling.\n",
    "\n",
    "    Args:\n",
    "        X: DataFrame to transform\n",
    "        verbose: If True, prints mapping statistics\n",
    "\n",
    "    Returns:\n",
    "        DataFrame with ordinal mappings applied\n",
    "    \"\"\"\n",
    "    X = X.copy()\n",
    "\n",
    "    for item in ORDINAL_MAPS:\n",
    "        ordinal_map = item[\"ordinalMap\"]\n",
    "\n",
    "        for col in item[\"columns\"]:\n",
    "            if col not in X.columns:\n",
    "                if verbose:\n",
    "                    print(f\"⚠️  Column '{col}' not found - skipping\")\n",
    "                continue\n",
    "\n",
    "            # Get original unique values\n",
    "            original_values = set(X[col].dropna().unique())\n",
    "            mapped_values = set(ordinal_map.keys()) - {np.nan}\n",
    "\n",
    "            # Check for unmapped values (excluding NaN)\n",
    "            unmapped = original_values - mapped_values\n",
    "            if unmapped and verbose:\n",
    "                print(f\"⚠️  Column '{col}' has unmapped values: {unmapped}\")\n",
    "\n",
    "            # Apply mapping\n",
    "            X[col] = X[col].map(ordinal_map)\n",
    "\n",
    "            if verbose:\n",
    "                print(\n",
    "                    f\"✓ Mapped '{col}': {len(original_values)} unique → numeric\")\n",
    "\n",
    "    return X\n",
    "\n",
    "\n",
    "X = map_ordinal(X)\n",
    "X_val = map_ordinal(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cfbf1fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.isna().sum()[lambda x:x > 0].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "773ece34",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(50, 50))\n",
    "sns.heatmap(X.corr(numeric_only=True), annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b5a34ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
    "\n",
    "\n",
    "def encode_OHE(X, fit=True):\n",
    "    categorical_columns = X.select_dtypes(\"object\").columns\n",
    "\n",
    "    one_hot_encoded = encoder.fit_transform(\n",
    "        X[categorical_columns]) if fit else encoder.transform(X[categorical_columns])\n",
    "\n",
    "    one_hot_X = pd.DataFrame(\n",
    "        one_hot_encoded, columns=encoder.get_feature_names_out(categorical_columns))\n",
    "\n",
    "    X_encoded = pd.concat([X.reset_index(\n",
    "        drop=True), one_hot_X.reset_index(drop=True)], axis=1)\n",
    "\n",
    "    X_encoded = X_encoded.drop(categorical_columns, axis=1)\n",
    "    return X_encoded\n",
    "\n",
    "\n",
    "X_encoded = encode_OHE(X)\n",
    "X_val_encoded = encode_OHE(X_val, fit=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ed1c6ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgbr = XGBRegressor(eval_metric=\"rmse\", early_stopping_rounds=100)\n",
    "\n",
    "# fit model no training data\n",
    "eval_set = [(X_encoded, y), (X_val_encoded, y_val)]\n",
    "xgbr.fit(X_encoded, y,\n",
    "         eval_set=eval_set,\n",
    "         verbose=False)\n",
    "# make predictions for test data\n",
    "y_pred = xgbr.predict(X_val_encoded)\n",
    "# evaluate predictions\n",
    "rmse = root_mean_squared_error(y_val, y_pred)\n",
    "print(f\"RMSE: {rmse}\")\n",
    "\n",
    "\n",
    "results = xgbr.evals_result()\n",
    "epochs = len(results['validation_0']['rmse'])\n",
    "x_axis = range(0, epochs)\n",
    "# plot rmse\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(x_axis, results['validation_0']['rmse'], label='Train')\n",
    "ax.plot(x_axis, results['validation_1']['rmse'], label='Test')\n",
    "ax.legend()\n",
    "\n",
    "plt.ylabel('RMSE')\n",
    "plt.title('XGBoost RMSE')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06e4d65a",
   "metadata": {},
   "source": [
    "Prepare df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfb85a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_test = df_test[\"Id\"]\n",
    "df_test = df_test.drop(DROPPED_COL, axis=1)\n",
    "df_test = map_ordinal(df_test)\n",
    "df_test_encoded = encode_OHE(df_test, fit=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a52997ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_submision = pd.DataFrame()\n",
    "df_submision[\"Id\"] = id_test\n",
    "df_submision[\"SalePrice\"] = xgbr.predict(df_test_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3f07884",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_submision.to_csv(\"sub4_test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bffa39fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features: 4684\n",
      "Training samples: 5834\n",
      "\n",
      "Training models...\n",
      "Training lasso...\n",
      "Training elasticnet...\n",
      "Training ridge...\n",
      "Training krr...\n",
      "Training svr...\n",
      "Training xgb1...\n",
      "Training xgb2...\n",
      "Training lgb1...\n",
      "Training lgb2...\n",
      "Training gbr...\n",
      "Training stacked models...\n",
      "\n",
      "Making predictions...\n",
      "\n",
      "============================================================\n",
      "Submission created!\n",
      "Predicted prices: $42275.01 to $678536.77\n",
      "Mean: $178671.93\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import Ridge, Lasso, ElasticNet\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.base import BaseEstimator, TransformerMixin, RegressorMixin, clone\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from scipy.stats import skew\n",
    "from scipy.special import boxcox1p\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Load data\n",
    "train = pd.read_csv(\n",
    "    r'D:\\dev\\python\\ai_ds_3projects\\house-prices\\datasets\\train_augmented_4x_rule_aware.csv')\n",
    "test = pd.read_csv(\n",
    "    r'D:\\dev\\python\\ai_ds_3projects\\house-prices\\datasets\\test.csv')\n",
    "\n",
    "# Save test IDs\n",
    "test_ID = test['Id']\n",
    "\n",
    "# Remove outliers - keep only the most extreme\n",
    "train = train.drop(train[(train['GrLivArea'] > 4000) &\n",
    "                   (train['SalePrice'] < 300000)].index)\n",
    "\n",
    "# Log transform target\n",
    "y_train = np.log1p(train['SalePrice'].values)\n",
    "\n",
    "# Combine train and test\n",
    "all_data = pd.concat((train, test)).reset_index(drop=True)\n",
    "all_data.drop(['SalePrice'], axis=1, inplace=True)\n",
    "\n",
    "# Handle missing values FIRST\n",
    "\n",
    "\n",
    "def handle_missing(df):\n",
    "    # Fill numeric with 0\n",
    "    for col in ['GarageYrBlt', 'GarageArea', 'GarageCars', 'BsmtFinSF1', 'BsmtFinSF2',\n",
    "                'BsmtUnfSF', 'TotalBsmtSF', 'BsmtFullBath', 'BsmtHalfBath', 'MasVnrArea']:\n",
    "        df[col].fillna(0, inplace=True)\n",
    "\n",
    "    # LotFrontage by neighborhood median\n",
    "    df['LotFrontage'] = df.groupby('Neighborhood')['LotFrontage'].transform(\n",
    "        lambda x: x.fillna(x.median()))\n",
    "\n",
    "    # Categorical with None\n",
    "    for col in ['PoolQC', 'MiscFeature', 'Alley', 'Fence', 'FireplaceQu', 'GarageType',\n",
    "                'GarageFinish', 'GarageQual', 'GarageCond', 'BsmtQual', 'BsmtCond',\n",
    "                'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2', 'MasVnrType', 'MSSubClass']:\n",
    "        df[col].fillna('None', inplace=True)\n",
    "\n",
    "    # Mode for these\n",
    "    for col in ['Functional', 'Electrical', 'KitchenQual', 'Exterior1st', 'Exterior2nd',\n",
    "                'SaleType', 'MSZoning', 'Utilities']:\n",
    "        if col in df.columns:\n",
    "            df[col].fillna(df[col].mode()[0] if len(\n",
    "                df[col].mode()) > 0 else 'None', inplace=True)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "all_data = handle_missing(all_data)\n",
    "\n",
    "# Label encoding for ordinal features\n",
    "ordinal_map = {\n",
    "    'ExterQual': {'Po': 1, 'Fa': 2, 'TA': 3, 'Gd': 4, 'Ex': 5},\n",
    "    'ExterCond': {'Po': 1, 'Fa': 2, 'TA': 3, 'Gd': 4, 'Ex': 5},\n",
    "    'BsmtQual': {'None': 0, 'Po': 1, 'Fa': 2, 'TA': 3, 'Gd': 4, 'Ex': 5},\n",
    "    'BsmtCond': {'None': 0, 'Po': 1, 'Fa': 2, 'TA': 3, 'Gd': 4, 'Ex': 5},\n",
    "    'BsmtExposure': {'None': 0, 'No': 1, 'Mn': 2, 'Av': 3, 'Gd': 4},\n",
    "    'BsmtFinType1': {'None': 0, 'Unf': 1, 'LwQ': 2, 'Rec': 3, 'BLQ': 4, 'ALQ': 5, 'GLQ': 6},\n",
    "    'BsmtFinType2': {'None': 0, 'Unf': 1, 'LwQ': 2, 'Rec': 3, 'BLQ': 4, 'ALQ': 5, 'GLQ': 6},\n",
    "    'HeatingQC': {'Po': 1, 'Fa': 2, 'TA': 3, 'Gd': 4, 'Ex': 5},\n",
    "    'KitchenQual': {'Po': 1, 'Fa': 2, 'TA': 3, 'Gd': 4, 'Ex': 5},\n",
    "    'Functional': {'Sal': 1, 'Sev': 2, 'Maj2': 3, 'Maj1': 4, 'Mod': 5, 'Min2': 6, 'Min1': 7, 'Typ': 8},\n",
    "    'FireplaceQu': {'None': 0, 'Po': 1, 'Fa': 2, 'TA': 3, 'Gd': 4, 'Ex': 5},\n",
    "    'GarageQual': {'None': 0, 'Po': 1, 'Fa': 2, 'TA': 3, 'Gd': 4, 'Ex': 5},\n",
    "    'GarageCond': {'None': 0, 'Po': 1, 'Fa': 2, 'TA': 3, 'Gd': 4, 'Ex': 5},\n",
    "    'PoolQC': {'None': 0, 'Fa': 1, 'TA': 2, 'Gd': 3, 'Ex': 4},\n",
    "    'Fence': {'None': 0, 'MnWw': 1, 'GdWo': 2, 'MnPrv': 3, 'GdPrv': 4}\n",
    "}\n",
    "\n",
    "for col, mapping in ordinal_map.items():\n",
    "    all_data[col] = all_data[col].map(mapping)\n",
    "\n",
    "# Feature Engineering\n",
    "\n",
    "\n",
    "def add_features(df):\n",
    "    # Total square footage\n",
    "    df['TotalSF'] = df['TotalBsmtSF'] + df['1stFlrSF'] + df['2ndFlrSF']\n",
    "\n",
    "    # Total bathrooms\n",
    "    df['TotalBath'] = df['FullBath'] + 0.5*df['HalfBath'] + \\\n",
    "        df['BsmtFullBath'] + 0.5*df['BsmtHalfBath']\n",
    "\n",
    "    # Total porch area\n",
    "    df['TotalPorchSF'] = df['OpenPorchSF'] + df['3SsnPorch'] + \\\n",
    "        df['EnclosedPorch'] + df['ScreenPorch'] + df['WoodDeckSF']\n",
    "\n",
    "    # Binary features\n",
    "    df['HasPool'] = (df['PoolArea'] > 0).astype(int)\n",
    "    df['Has2ndFloor'] = (df['2ndFlrSF'] > 0).astype(int)\n",
    "    df['HasGarage'] = (df['GarageArea'] > 0).astype(int)\n",
    "    df['HasBsmt'] = (df['TotalBsmtSF'] > 0).astype(int)\n",
    "    df['HasFireplace'] = (df['Fireplaces'] > 0).astype(int)\n",
    "\n",
    "    # Age features\n",
    "    df['HouseAge'] = df['YrSold'] - df['YearBuilt']\n",
    "    df['RemodAge'] = df['YrSold'] - df['YearRemodAdd']\n",
    "    df['IsNew'] = (df['YearBuilt'] >= 2000).astype(int)\n",
    "    df['IsRemodeled'] = (df['YearBuilt'] != df['YearRemodAdd']).astype(int)\n",
    "\n",
    "    # Key quality interactions\n",
    "    df['OverallQual_TotalSF'] = df['OverallQual'] * df['TotalSF']\n",
    "    df['OverallQual_GrLivArea'] = df['OverallQual'] * df['GrLivArea']\n",
    "    df['OverallQual_TotalBath'] = df['OverallQual'] * df['TotalBath']\n",
    "    df['OverallQual_GarageCars'] = df['OverallQual'] * df['GarageCars']\n",
    "    df['ExterQual_TotalSF'] = df['ExterQual'] * df['TotalSF']\n",
    "    df['KitchenQual_TotalSF'] = df['KitchenQual'] * df['TotalSF']\n",
    "    df['BsmtQual_TotalBsmtSF'] = df['BsmtQual'] * df['TotalBsmtSF']\n",
    "\n",
    "    # Area ratios\n",
    "    df['LivingArea_Ratio'] = df['GrLivArea'] / (df['TotalSF'] + 1)\n",
    "    df['Bsmt_Ratio'] = df['TotalBsmtSF'] / (df['TotalSF'] + 1)\n",
    "    df['GarageArea_Ratio'] = df['GarageArea'] / (df['TotalSF'] + 1)\n",
    "\n",
    "    # Quality scores\n",
    "    df['TotalQual'] = df['OverallQual'] + df['OverallCond']\n",
    "    df['QualityScore'] = df['ExterQual'] + \\\n",
    "        df['KitchenQual'] + df['BsmtQual'] + df['GarageQual']\n",
    "\n",
    "    # Polynomial features for key variables\n",
    "    df['GrLivArea_Squared'] = df['GrLivArea'] ** 2\n",
    "    df['TotalSF_Squared'] = df['TotalSF'] ** 2\n",
    "    df['OverallQual_Squared'] = df['OverallQual'] ** 2\n",
    "    df['OverallQual_Cubed'] = df['OverallQual'] ** 3\n",
    "\n",
    "    # Total living area\n",
    "    df['TotalLivingArea'] = df['GrLivArea'] + df['TotalBsmtSF']\n",
    "\n",
    "    # Room size\n",
    "    df['AvgRoomSize'] = df['GrLivArea'] / (df['TotRmsAbvGrd'] + 1)\n",
    "\n",
    "    # Bathroom to room ratio\n",
    "    df['Bath_Room_Ratio'] = df['TotalBath'] / (df['TotRmsAbvGrd'] + 1)\n",
    "\n",
    "    # Garage interaction\n",
    "    df['GarageCars_Area'] = df['GarageCars'] * df['GarageArea']\n",
    "\n",
    "    # Year sold features\n",
    "    df['SoldRecent'] = (df['YrSold'] >= 2008).astype(int)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "# Apply feature engineering\n",
    "all_data = add_features(all_data)\n",
    "\n",
    "# Convert to categorical\n",
    "all_data['MSSubClass'] = all_data['MSSubClass'].astype(str)\n",
    "all_data['OverallCond'] = all_data['OverallCond'].astype(str)\n",
    "all_data['YrSold'] = all_data['YrSold'].astype(str)\n",
    "all_data['MoSold'] = all_data['MoSold'].astype(str)\n",
    "\n",
    "# Get dummy variables\n",
    "all_data = pd.get_dummies(all_data)\n",
    "all_data.drop(['Id'], axis=1, inplace=True)\n",
    "\n",
    "# Fix skewness with more aggressive threshold\n",
    "numeric_feats = all_data.dtypes[all_data.dtypes != \"object\"].index\n",
    "skewed_feats = all_data[numeric_feats].apply(\n",
    "    lambda x: skew(x.dropna())).sort_values(ascending=False)\n",
    "skewness = pd.DataFrame({'Skew': skewed_feats})\n",
    "skewness = skewness[abs(skewness) > 0.75]\n",
    "\n",
    "skewed_features = skewness.index\n",
    "lam = 0.15\n",
    "for feat in skewed_features:\n",
    "    all_data[feat] = boxcox1p(all_data[feat], lam)\n",
    "\n",
    "# Split back and ensure no NaN\n",
    "X_train = all_data[:len(y_train)].fillna(0)\n",
    "X_test = all_data[len(y_train):].fillna(0)\n",
    "\n",
    "print(f\"Features: {X_train.shape[1]}\")\n",
    "print(f\"Training samples: {X_train.shape[0]}\")\n",
    "\n",
    "# Advanced Stacking Class\n",
    "\n",
    "\n",
    "class StackingAveragedModels(BaseEstimator, RegressorMixin, TransformerMixin):\n",
    "    def __init__(self, base_models, meta_model, n_folds=10):\n",
    "        self.base_models = base_models\n",
    "        self.meta_model = meta_model\n",
    "        self.n_folds = n_folds\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.base_models_ = [list() for x in self.base_models]\n",
    "        self.meta_model_ = clone(self.meta_model)\n",
    "        kfold = KFold(n_splits=self.n_folds, shuffle=True, random_state=42)\n",
    "\n",
    "        out_of_fold_predictions = np.zeros((X.shape[0], len(self.base_models)))\n",
    "        for i, model in enumerate(self.base_models):\n",
    "            for train_index, holdout_index in kfold.split(X, y):\n",
    "                instance = clone(model)\n",
    "                self.base_models_[i].append(instance)\n",
    "                instance.fit(X.iloc[train_index], y[train_index])\n",
    "                y_pred = instance.predict(X.iloc[holdout_index])\n",
    "                out_of_fold_predictions[holdout_index, i] = y_pred\n",
    "\n",
    "        self.meta_model_.fit(out_of_fold_predictions, y)\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        meta_features = np.column_stack([\n",
    "            np.column_stack([model.predict(X)\n",
    "                            for model in base_models]).mean(axis=1)\n",
    "            for base_models in self.base_models_])\n",
    "        return self.meta_model_.predict(meta_features)\n",
    "\n",
    "\n",
    "# Define models with even better hyperparameters\n",
    "lasso = make_pipeline(RobustScaler(), Lasso(\n",
    "    alpha=0.00045, random_state=1, max_iter=50000))\n",
    "elasticnet = make_pipeline(RobustScaler(), ElasticNet(\n",
    "    alpha=0.00045, l1_ratio=0.85, random_state=3, max_iter=50000))\n",
    "ridge = make_pipeline(RobustScaler(), Ridge(alpha=12, random_state=1))\n",
    "krr = KernelRidge(alpha=0.65, kernel='polynomial', degree=2, coef0=2.5)\n",
    "\n",
    "# XGBoost with stronger regularization\n",
    "xgb1 = xgb.XGBRegressor(\n",
    "    colsample_bytree=0.4, gamma=0.045, learning_rate=0.04,\n",
    "    max_depth=2, min_child_weight=1.5, n_estimators=3000,\n",
    "    reg_alpha=0.6, reg_lambda=0.95, subsample=0.5,\n",
    "    random_state=7, n_jobs=-1, verbosity=0\n",
    ")\n",
    "\n",
    "xgb2 = xgb.XGBRegressor(\n",
    "    colsample_bytree=0.45, gamma=0.05, learning_rate=0.035,\n",
    "    max_depth=3, min_child_weight=2, n_estimators=3500,\n",
    "    reg_alpha=0.55, reg_lambda=1.0, subsample=0.52,\n",
    "    random_state=42, n_jobs=-1, verbosity=0\n",
    ")\n",
    "\n",
    "# LightGBM with better parameters\n",
    "lgb1 = lgb.LGBMRegressor(\n",
    "    objective='regression', num_leaves=4, learning_rate=0.04,\n",
    "    n_estimators=900, max_bin=55, bagging_fraction=0.75,\n",
    "    bagging_freq=5, feature_fraction=0.22,\n",
    "    min_data_in_leaf=5, min_sum_hessian_in_leaf=10,\n",
    "    reg_alpha=0.6, reg_lambda=0.8,\n",
    "    random_state=7, verbosity=-1\n",
    ")\n",
    "\n",
    "lgb2 = lgb.LGBMRegressor(\n",
    "    objective='regression', num_leaves=5, learning_rate=0.035,\n",
    "    n_estimators=1200, max_bin=200, bagging_fraction=0.7,\n",
    "    bagging_freq=7, feature_fraction=0.23,\n",
    "    min_data_in_leaf=6, min_sum_hessian_in_leaf=11,\n",
    "    reg_alpha=0.65, reg_lambda=0.85,\n",
    "    random_state=42, verbosity=-1\n",
    ")\n",
    "\n",
    "# GradientBoosting with deeper trees\n",
    "gbr = GradientBoostingRegressor(\n",
    "    n_estimators=4000, learning_rate=0.04, max_depth=3,\n",
    "    max_features='sqrt', min_samples_leaf=12, min_samples_split=8,\n",
    "    loss='huber', random_state=5, subsample=0.8\n",
    ")\n",
    "\n",
    "# SVR\n",
    "svr_model = make_pipeline(RobustScaler(), SVR(\n",
    "    C=25, epsilon=0.009, gamma=0.0004))\n",
    "\n",
    "# Create multiple stacked ensembles\n",
    "stacked_model1 = StackingAveragedModels(\n",
    "    base_models=(elasticnet, krr, xgb1, lgb1),\n",
    "    meta_model=ridge\n",
    ")\n",
    "\n",
    "stacked_model2 = StackingAveragedModels(\n",
    "    base_models=(lasso, gbr, xgb2, lgb2),\n",
    "    meta_model=elasticnet\n",
    ")\n",
    "\n",
    "# Train all models\n",
    "print(\"\\nTraining models...\")\n",
    "models_to_train = {\n",
    "    'lasso': lasso,\n",
    "    'elasticnet': elasticnet,\n",
    "    'ridge': ridge,\n",
    "    'krr': krr,\n",
    "    'svr': svr_model,\n",
    "    'xgb1': xgb1,\n",
    "    'xgb2': xgb2,\n",
    "    'lgb1': lgb1,\n",
    "    'lgb2': lgb2,\n",
    "    'gbr': gbr\n",
    "}\n",
    "\n",
    "trained = {}\n",
    "for name, model in models_to_train.items():\n",
    "    print(f\"Training {name}...\")\n",
    "    model.fit(X_train, y_train)\n",
    "    trained[name] = model\n",
    "\n",
    "print(\"Training stacked models...\")\n",
    "stacked_model1.fit(X_train, y_train)\n",
    "stacked_model2.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "print(\"\\nMaking predictions...\")\n",
    "preds = {name: model.predict(X_test) for name, model in trained.items()}\n",
    "stacked_pred1 = stacked_model1.predict(X_test)\n",
    "stacked_pred2 = stacked_model2.predict(X_test)\n",
    "\n",
    "# Multi-level ensemble with optimized weights\n",
    "final_pred = (\n",
    "    0.30 * stacked_pred1 +\n",
    "    0.25 * stacked_pred2 +\n",
    "    0.12 * preds['xgb1'] +\n",
    "    0.12 * preds['lgb1'] +\n",
    "    0.08 * preds['xgb2'] +\n",
    "    0.08 * preds['lgb2'] +\n",
    "    0.05 * preds['ridge']\n",
    ")\n",
    "\n",
    "final_pred = np.expm1(final_pred)\n",
    "\n",
    "# Create submission\n",
    "submission = pd.DataFrame({'Id': test_ID, 'SalePrice': final_pred})\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Submission created!\")\n",
    "print(f\"Predicted prices: ${final_pred.min():.2f} to ${final_pred.max():.2f}\")\n",
    "print(f\"Mean: ${final_pred.mean():.2f}\")\n",
    "print(\"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai-ds-projects (3.12.6)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
